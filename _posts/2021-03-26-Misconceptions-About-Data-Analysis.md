---
layout: post
title: "Misconceptions About Data Analysis"
date: 2021-03-26
---
The problem of disability to reproduce a large percentage of published finding is fully discussed in the article written by Henry J. Motulsky. The article pointed out that, rather than having a clear understanding of statistical concepts, investigators often make mistakes due to misconceptions. Among all those possible mistakes, the one worth great noticing is the overemphasis on P value.
In previous statistics classes, we always pay great attentions on P value and its common threshold 0.05. However, in the article, Moltulsky states that P value greatly depends on sample size, which may lead to both overestimation on small P value and underestimation on big P value. He implied this by comparing experiments with different sample size but the same P value. To conclude, although with a same P value, experiment with larger sample size has a narrower confidence interval, which means its proof of effect is much solider than another one.
To sum up, P value is not effective unless the sample size is big enough. Thus, as a mention, we should always show the sample size and confidence interval when doing a significant test or comparing P-values. Also, according to Motulsky’s suggestion, I shall consider omitting reporting some unnecessary P values. This may give readers a choice to interpret the research findings more objectively. 

Reference:
Motulsky, H. J. (2014). Common misconceptions about data analysis and statistics. Naunyn-Schmiedeberg’s Archives of Pharmacology, 387(11), 1017–1023. https://doi.org/10.1007/s00210-014-1037-6
